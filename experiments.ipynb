{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcc/Documents/msc/courses/c550/nlp/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pickle\n",
    "import copy\n",
    "from utils.metrics import get_recall_at_100, get_nDCG_at_10\n",
    "\n",
    "from main import get_query_expansion_dataset, run_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up LLM, assumes that openai API key is stored in .env file\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Miracl dataset (english version)\n",
    "dataset = load_dataset(\"Cohere/miracl-en-queries-22-12\", split=\"dev\")\n",
    "dataset = dataset.to_pandas().to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: BM25 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 799/799 [01:24<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.8190\n",
      "BM25 nDCG@10: 0.3506\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BM25\n",
    "searcher = LuceneSearcher.from_prebuilt_index('miracl-v1.0-en')\n",
    "recall_baseline, ndcg_baseline = run_search(searcher, dataset)\n",
    "print(f'BM25 Recall@100: {recall_baseline:.4f}')\n",
    "print(f'BM25 nDCG@10: {ndcg_baseline:.4f}')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Zero-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 799/799 [05:35<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.7777\n",
      "BM25 nDCG@10: 0.3480\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "searcher = LuceneSearcher.from_prebuilt_index('miracl-v1.0-en')\n",
    "data_expanded_zero_shot = get_query_expansion_dataset(dataset, option='zero-shot')\n",
    "#data_expanded_zero_shot_test = get_query_expansion_dataset(dataset[:10], option='zero-shot')\n",
    "\n",
    "recall_zs, ndcg_zs = run_search(searcher, data_expanded_zero_shot)\n",
    "print(f'BM25 Recall@100: {recall_zs:.4f}')\n",
    "print(f'BM25 nDCG@10: {ndcg_zs:.4f}')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: One-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching:   0%|          | 0/799 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 799/799 [02:15<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.7485\n",
      "BM25 nDCG@10: 0.3198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BM25\n",
    "searcher = LuceneSearcher.from_prebuilt_index('miracl-v1.0-en')\n",
    "data_expanded_one_shot = get_query_expansion_dataset(dataset, option='one-shot')\n",
    "\n",
    "recall_os, ndcg_os = run_search(searcher, data_expanded_one_shot)\n",
    "print(f'BM25 Recall@100: {recall_os:.4f}')\n",
    "print(f'BM25 nDCG@10: {ndcg_os:.4f}')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 799/799 [02:03<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.7825\n",
      "BM25 nDCG@10: 0.3486\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "searcher = LuceneSearcher.from_prebuilt_index('miracl-v1.0-en')\n",
    "data_expanded_multi_shot = get_query_expansion_dataset(dataset, option='multi-shot')\n",
    "\n",
    "recall_ms, ndcg_ms = run_search(searcher, data_expanded_multi_shot)\n",
    "print(f'BM25 Recall@100: {recall_ms:.4f}')\n",
    "print(f'BM25 nDCG@10: {ndcg_ms:.4f}')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5: Answer prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 799/799 [07:07<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.7361\n",
      "BM25 nDCG@10: 0.3960\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "searcher = LuceneSearcher.from_prebuilt_index('miracl-v1.0-en')\n",
    "data_expanded_answer = get_query_expansion_dataset(dataset, option='answer')\n",
    "\n",
    "recall_ans, ndcg_ans = run_search(searcher, data_expanded_answer)\n",
    "print(f'BM25 Recall@100: {recall_ans:.4f}')\n",
    "print(f'BM25 nDCG@10: {ndcg_ans:.4f}')\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
