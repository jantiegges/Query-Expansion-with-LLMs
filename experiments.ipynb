{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jantiegges/.pyenv/versions/3.10.13/envs/550-final/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI, ChatCohere, ChatAnyscale\n",
    "\n",
    "from main import get_query_expansion_dataset, run_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up LLMs, assumes that API keys are stored in .env file\n",
    "load_dotenv(override=True)\n",
    "chats = {}\n",
    "\n",
    "# OpenAI\n",
    "try: \n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    chat_openai = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-3.5-turbo\")\n",
    "    chats[\"OpenAI\"] = chat_openai\n",
    "except:\n",
    "    print(\"Could not initialize OpenAI chatbot. Please store a valid API key in a .env file.\")\n",
    "\n",
    "# Cohere\n",
    "try:\n",
    "    cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    chat_cohere = ChatCohere(cohere_api_key=cohere_api_key)\n",
    "    chats[\"Cohere\"] = chat_cohere\n",
    "except:\n",
    "    print(\"Could not initialize Cohere chatbot. Please store a valid API key in a .env file.\")\n",
    "\n",
    "# Llama 2 (Anyscale)\n",
    "try: \n",
    "    anyscale_api_key = os.getenv(\"ANYSCALE_API_KEY\")\n",
    "    chat_llama = ChatAnyscale(model_name=\"meta-llama/Llama-2-7b-chat-hf\", anyscale_api_key=anyscale_api_key)\n",
    "    chats[\"Llama 2\"] = chat_llama\n",
    "except:\n",
    "    print(\"Could not initialize Anyscale chatbot. Please store a valid API key in a .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments Set 1: All prompts, english language, all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Miracl dataset (english version)\n",
    "dataset = load_dataset(\"Cohere/miracl-en-queries-22-12\", split=\"dev\")\n",
    "dataset = dataset.to_pandas().to_dict(orient='records')\n",
    "\n",
    "# set up searcher\n",
    "searcher = LuceneSearcher.from_prebuilt_index('miracl-v1.0-en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_baseline, ndcg_baseline = run_search(searcher, dataset)\n",
    "\n",
    "print(f'BM25 Recall@100: {recall_baseline:.4f}')\n",
    "print(f'BM25 nDCG@10: {ndcg_baseline:.4f}')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Query2Doc Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 5/5 [01:10<00:00, 14.11s/it]\n",
      "Searching: 100%|██████████| 5/5 [00:14<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Recall@100: 0.8333\n",
      "OpenAI nDCG@10: 0.2921\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 5/5 [01:06<00:00, 13.30s/it]\n",
      "Searching: 100%|██████████| 5/5 [00:17<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere Recall@100: 0.7667\n",
      "Cohere nDCG@10: 0.3049\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 5/5 [00:27<00:00,  5.52s/it]\n",
      "Searching: 100%|██████████| 5/5 [00:08<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 Recall@100: 0.7667\n",
      "Llama 2 nDCG@10: 0.3563\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_name, chat in chats.items():\n",
    "    expanded_dataset = get_query_expansion_dataset(dataset, chat, chat_name, lang='en', prompt='q2d-zs')\n",
    "\n",
    "    recall, ndcg = run_search(searcher, expanded_dataset)\n",
    "    print(f'{chat_name} Recall@100: {recall:.4f}') \n",
    "    print(f'{chat_name} nDCG@10: {ndcg:.4f}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Q2D zero shot prompting with pseudo-relevant feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prf documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 5/5 [00:00<00:00, 72.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 5/5 [00:52<00:00, 10.54s/it]\n",
      "Searching: 100%|██████████| 5/5 [00:08<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.9000\n",
      "BM25 nDCG@10: 0.3924\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_name, chat in chats.items():\n",
    "    expanded_dataset = get_query_expansion_dataset(dataset, chat, chat_name, lang='en', prompt='q2d-zs-prf')\n",
    "\n",
    "    recall, ndcg = run_search(searcher, expanded_dataset)\n",
    "    print(f'{chat_name} Recall@100: {recall:.4f}') \n",
    "    print(f'{chat_name} nDCG@10: {ndcg:.4f}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Keywords with zero-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries:   0%|          | 0/799 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 799/799 [54:50<00:00,  4.12s/it]  \n",
      "Searching: 100%|██████████| 799/799 [01:25<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.8433\n",
      "BM25 nDCG@10: 0.3745\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_name, chat in chats.items():\n",
    "    expanded_dataset = get_query_expansion_dataset(dataset, chat, chat_name, lang='en', prompt='q2e-zs')\n",
    "\n",
    "    recall, ndcg = run_search(searcher, expanded_dataset)\n",
    "    print(f'{chat_name} Recall@100: {recall:.4f}') \n",
    "    print(f'{chat_name} nDCG@10: {ndcg:.4f}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Keywords with pseudo-relevant feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prf documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching:  11%|█         | 89/799 [00:02<00:28, 25.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 799/799 [00:26<00:00, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 799/799 [1:02:36<00:00,  4.70s/it]\n",
      "Searching: 100%|██████████| 799/799 [02:56<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.8337\n",
      "BM25 nDCG@10: 0.3722\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_name, chat in chats.items():\n",
    "    expanded_dataset = get_query_expansion_dataset(dataset, chat, chat_name, lang='en', prompt='q2e-zs-prf')\n",
    "\n",
    "    recall, ndcg = run_search(searcher, expanded_dataset)\n",
    "    print(f'{chat_name} Recall@100: {recall:.4f}') \n",
    "    print(f'{chat_name} nDCG@10: {ndcg:.4f}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Chain of thought prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching:   0%|          | 0/799 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 799/799 [30:35<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.8866\n",
      "BM25 nDCG@10: 0.4877\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_name, chat in chats.items():\n",
    "    expanded_dataset = get_query_expansion_dataset(dataset, chat, chat_name, lang='en', prompt='chain-of-thought')\n",
    "\n",
    "    recall, ndcg = run_search(searcher, expanded_dataset)\n",
    "    print(f'{chat_name} Recall@100: {recall:.4f}') \n",
    "    print(f'{chat_name} nDCG@10: {ndcg:.4f}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Chain of thought prompting with psuedo-relevant feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prf documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 799/799 [00:30<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 799/799 [1:41:54<00:00,  7.65s/it]  \n",
      "Searching: 100%|██████████| 799/799 [09:45<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Recall@100: 0.8486\n",
      "BM25 nDCG@10: 0.4343\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_name, chat in chats.items():\n",
    "    expanded_dataset = get_query_expansion_dataset(dataset, chat, chat_name, lang='en', prompt='chain-of-thought-prf')\n",
    "\n",
    "    recall, ndcg = run_search(searcher, expanded_dataset)\n",
    "    print(f'{chat_name} Recall@100: {recall:.4f}') \n",
    "    print(f'{chat_name} nDCG@10: {ndcg:.4f}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Set 2: Chain-of-thought prompt, various languages, all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Miracl dataset (english version)\n",
    "dataset = load_dataset(\"Cohere/miracl-fr-queries-22-12\", split=\"dev\")\n",
    "dataset = dataset.to_pandas().to_dict(orient='records')\n",
    "\n",
    "# set up searcher\n",
    "searcher = LuceneSearcher.from_prebuilt_index('miracl-v1.0-fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 10/10 [05:21<00:00, 32.13s/it]\n",
      "Searching: 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Recall@100: 0.4667\n",
      "OpenAI nDCG@10: 0.1103\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 10/10 [02:48<00:00, 16.85s/it]\n",
      "Searching: 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere Recall@100: 0.2967\n",
      "Cohere nDCG@10: 0.0219\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding queries: 100%|██████████| 10/10 [01:25<00:00,  8.51s/it]\n",
      "Searching: 100%|██████████| 10/10 [00:05<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 Recall@100: 0.2583\n",
      "Llama 2 nDCG@10: 0.0429\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_name, chat in chats.items():\n",
    "    expanded_dataset = get_query_expansion_dataset(dataset[:10], chat, chat_name, lang='fr', prompt='chain-of-thought-fr')\n",
    "\n",
    "    recall, ndcg = run_search(searcher, expanded_dataset)\n",
    "    print(f'{chat_name} Recall@100: {recall:.4f}') \n",
    "    print(f'{chat_name} nDCG@10: {ndcg:.4f}')\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
